{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMAKMjwOI7qyNS3EVojxP5c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-G_iZ5i6qhTn","executionInfo":{"status":"ok","timestamp":1751273827573,"user_tz":-420,"elapsed":976396,"user":{"displayName":"RIO LIANDO ANGGERI -","userId":"11047377438386479425"}},"outputId":"a7475ba0-08be-428f-f6e9-74860a6ad4ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.2559 - val_loss: 0.0549\n","Epoch 2/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0529 - val_loss: 0.0462\n","Epoch 3/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0436 - val_loss: 0.0397\n","Epoch 4/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0391 - val_loss: 0.0381\n","Epoch 5/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0381 - val_loss: 0.0377\n","Epoch 6/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0377 - val_loss: 0.0375\n","Epoch 7/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0375 - val_loss: 0.0372\n","Epoch 8/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0373 - val_loss: 0.0371\n","Epoch 9/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0372 - val_loss: 0.0372\n","Epoch 10/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0371 - val_loss: 0.0369\n","Epoch 11/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0370 - val_loss: 0.0368\n","Epoch 12/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0369 - val_loss: 0.0368\n","Epoch 13/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0368 - val_loss: 0.0362\n","Epoch 14/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0345 - val_loss: 0.0325\n","Epoch 15/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0322 - val_loss: 0.0315\n","Epoch 16/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0316 - val_loss: 0.0312\n","Epoch 17/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0314 - val_loss: 0.0309\n","Epoch 18/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0306 - val_loss: 0.0305\n","Epoch 19/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0303 - val_loss: 0.0302\n","Epoch 20/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0302 - val_loss: 0.0302\n","Epoch 21/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0300 - val_loss: 0.0303\n","Epoch 22/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0300 - val_loss: 0.0299\n","Epoch 23/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0299 - val_loss: 0.0300\n","Epoch 24/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0299 - val_loss: 0.0301\n","Epoch 25/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0298 - val_loss: 0.0300\n","Epoch 26/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0298 - val_loss: 0.0298\n","Epoch 27/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0298 - val_loss: 0.0299\n","Epoch 28/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0298 - val_loss: 0.0297\n","Epoch 29/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0298 - val_loss: 0.0301\n","Epoch 30/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0297 - val_loss: 0.0298\n","Epoch 31/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0296 - val_loss: 0.0297\n","Epoch 32/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0296 - val_loss: 0.0292\n","Epoch 33/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0290 - val_loss: 0.0289\n","Epoch 34/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0287 - val_loss: 0.0291\n","Epoch 35/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0287 - val_loss: 0.0288\n","Epoch 36/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0286 - val_loss: 0.0286\n","Epoch 37/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0286 - val_loss: 0.0283\n","Epoch 38/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0282 - val_loss: 0.0272\n","Epoch 39/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0267 - val_loss: 0.0252\n","Epoch 40/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0249 - val_loss: 0.0241\n","Epoch 41/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0241 - val_loss: 0.0238\n","Epoch 42/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0238 - val_loss: 0.0236\n","Epoch 43/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0237 - val_loss: 0.0236\n","Epoch 44/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0236 - val_loss: 0.0238\n","Epoch 45/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0235 - val_loss: 0.0235\n","Epoch 46/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0235 - val_loss: 0.0239\n","Epoch 47/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0234 - val_loss: 0.0235\n","Epoch 48/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0234 - val_loss: 0.0234\n","Epoch 49/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0234 - val_loss: 0.0234\n","Epoch 50/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0234 - val_loss: 0.0233\n","Epoch 51/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0234 - val_loss: 0.0234\n","Epoch 52/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0233 - val_loss: 0.0237\n","Epoch 53/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0234 - val_loss: 0.0236\n","Epoch 54/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0234 - val_loss: 0.0233\n","Epoch 55/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0233 - val_loss: 0.0233\n","Epoch 56/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0233 - val_loss: 0.0235\n","Epoch 57/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0233 - val_loss: 0.0232\n","Epoch 58/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0233 - val_loss: 0.0235\n","Epoch 59/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0233 - val_loss: 0.0231\n","Epoch 60/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0232 - val_loss: 0.0237\n","Epoch 61/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0232 - val_loss: 0.0233\n","Epoch 62/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0230 - val_loss: 0.0234\n","Epoch 63/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0230 - val_loss: 0.0230\n","Epoch 64/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0230 - val_loss: 0.0229\n","Epoch 65/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0230 - val_loss: 0.0238\n","Epoch 66/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0230 - val_loss: 0.0229\n","Epoch 67/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0230 - val_loss: 0.0231\n","Epoch 68/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0230 - val_loss: 0.0236\n","Epoch 69/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0230 - val_loss: 0.0234\n","Epoch 70/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0230 - val_loss: 0.0230\n","Epoch 71/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0230 - val_loss: 0.0233\n","\u001b[1m7928/7928\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 806us/step\n","✅ Dataset latent berhasil disimpan.\n"]}],"source":["# 0. Mounting Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 1. Import Libraries\n","import numpy as np\n","import pandas as pd\n","import os\n","import random\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, RobustScaler\n","from scipy.stats.mstats import winsorize\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, LeakyReLU\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# 2. Set Seed untuk Konsistensi\n","SEED = 44\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","\n","# 3. Load Dataset\n","data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Skripsi/Dataset/diabetes_012_health_indicators_BRFSS2015.csv')\n","X = data.drop('Diabetes_012', axis=1)\n","\n","# 4. Preprocessing (Sesuai Model Default)\n","X['BMI'] = winsorize(X['BMI'], limits=[0.005, 0.005])\n","X['MentHlth'] = np.where(X['MentHlth'] > 30, 30, X['MentHlth'])\n","X['PhysHlth'] = np.where(X['PhysHlth'] > 30, 30, X['PhysHlth'])\n","\n","robust_features = ['BMI', 'MentHlth', 'PhysHlth']\n","minmax_features = ['Age', 'Education', 'Income', 'GenHlth']\n","\n","scaler_robust = RobustScaler()\n","scaler_minmax = MinMaxScaler()\n","\n","X[robust_features] = scaler_robust.fit_transform(X[robust_features])\n","X[minmax_features] = scaler_minmax.fit_transform(X[minmax_features])\n","\n","# 5. Split Data untuk AE (tidak butuh label y)\n","X_train_ae, X_test_ae = train_test_split(X, test_size=0.2, random_state=SEED)\n","\n","# 6. Build Autoencoder AE B2 dengan LeakyReLU\n","input_dim = X.shape[1]\n","input_layer = Input(shape=(input_dim,))\n","\n","# Encoder\n","x = Dense(16)(input_layer)\n","x = LeakyReLU(alpha=0.1)(x)\n","x = Dense(12)(x)\n","x = LeakyReLU(alpha=0.1)(x)\n","\n","# Latent space\n","latent = Dense(10)(x)\n","latent = LeakyReLU(alpha=0.1)(latent)\n","\n","# Decoder\n","x = Dense(12)(latent)\n","x = LeakyReLU(alpha=0.1)(x)\n","x = Dense(16)(x)\n","x = LeakyReLU(alpha=0.1)(x)\n","\n","# Output layer\n","output_layer = Dense(input_dim, activation='linear')(x)\n","\n","# Autoencoder model\n","autoencoder = Model(inputs=input_layer, outputs=output_layer)\n","autoencoder.compile(optimizer='adam', loss='mse')\n","\n","# 7. Train Autoencoder\n","history = autoencoder.fit(\n","    X_train_ae, X_train_ae,\n","    validation_data=(X_test_ae, X_test_ae),\n","    epochs=100,\n","    batch_size=50,\n","    verbose=1,\n","    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",")\n","\n","# 8. Simpan Model\n","save_dir = '/content/drive/MyDrive/Colab Notebooks/Skripsi/Model/Model Autoencoders'\n","os.makedirs(save_dir, exist_ok=True)\n","# autoencoder.save(f'{save_dir}/aeb2_model_leakyrelu.h5')\n","\n","# 9. Ekstrak Encoder dari Autoencoder\n","encoder = Model(inputs=input_layer, outputs=latent)\n","\n","# 10. Transformasi seluruh data X menjadi bentuk laten\n","X_latent = encoder.predict(X)\n","\n","# 11. Buat DataFrame hasil reduksi dimensi\n","latent_df = pd.DataFrame(X_latent, columns=[f'Latent_{i+1}' for i in range(X_latent.shape[1])])\n","\n","# 12. Tambahkan label (opsional)\n","latent_df['Diabetes_012'] = data['Diabetes_012']\n","\n","# 13. Simpan ke direktori yang ditentukan\n","output_path = '/content/drive/MyDrive/Colab Notebooks/Skripsi/Dataset/V2 Hasil Eksperimen/AE'\n","os.makedirs(output_path, exist_ok=True)\n","latent_df.to_csv(f'{output_path}/AEB2_dataset_latent.csv', index=False)\n","\n","print(\"✅ Dataset latent berhasil disimpan.\")\n"]}]}