{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iNh74rgx0bEw","executionInfo":{"status":"ok","timestamp":1751275769033,"user_tz":-420,"elapsed":582441,"user":{"displayName":"RIO LIANDO ANGGERI -","userId":"11047377438386479425"}},"outputId":"2a42ae03-0ae7-4500-ac38-6175ec8742e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.2806 - val_loss: 0.0648\n","Epoch 2/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0627 - val_loss: 0.0578\n","Epoch 3/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0578 - val_loss: 0.0570\n","Epoch 4/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0572 - val_loss: 0.0554\n","Epoch 5/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0524 - val_loss: 0.0484\n","Epoch 6/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0485 - val_loss: 0.0482\n","Epoch 7/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0483 - val_loss: 0.0481\n","Epoch 8/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0482 - val_loss: 0.0480\n","Epoch 9/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0482 - val_loss: 0.0480\n","Epoch 10/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0481 - val_loss: 0.0480\n","Epoch 11/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0481 - val_loss: 0.0479\n","Epoch 12/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0481 - val_loss: 0.0479\n","Epoch 13/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0480 - val_loss: 0.0478\n","Epoch 14/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0480 - val_loss: 0.0477\n","Epoch 15/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0479 - val_loss: 0.0476\n","Epoch 16/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0475 - val_loss: 0.0450\n","Epoch 17/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0440 - val_loss: 0.0424\n","Epoch 18/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0399\n","Epoch 19/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0399 - val_loss: 0.0397\n","Epoch 20/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0396 - val_loss: 0.0404\n","Epoch 21/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0395 - val_loss: 0.0396\n","Epoch 22/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0394 - val_loss: 0.0394\n","Epoch 23/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0394 - val_loss: 0.0394\n","Epoch 24/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0394 - val_loss: 0.0394\n","Epoch 25/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0394 - val_loss: 0.0394\n","Epoch 26/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0393 - val_loss: 0.0393\n","Epoch 27/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0393 - val_loss: 0.0395\n","Epoch 28/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0393 - val_loss: 0.0397\n","Epoch 29/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0393 - val_loss: 0.0397\n","Epoch 30/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0393 - val_loss: 0.0394\n","Epoch 31/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0393 - val_loss: 0.0394\n","\u001b[1m7928/7928\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n","✅ Dataset latent berhasil disimpan dengan LeakyReLU.\n"]}],"source":["# 0. Mounting Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 1. Import Libraries\n","import numpy as np\n","import pandas as pd\n","import os\n","import random\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, RobustScaler\n","from scipy.stats.mstats import winsorize\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, LeakyReLU\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# 2. Set Seed untuk Konsistensi\n","SEED = 44\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","\n","# 3. Load Dataset\n","data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Skripsi/Dataset/diabetes_012_health_indicators_BRFSS2015.csv')\n","X = data.drop('Diabetes_012', axis=1)\n","\n","# 4. Preprocessing (Sesuai Model Default)\n","X['BMI'] = winsorize(X['BMI'], limits=[0.005, 0.005])\n","X['MentHlth'] = np.where(X['MentHlth'] > 30, 30, X['MentHlth'])\n","X['PhysHlth'] = np.where(X['PhysHlth'] > 30, 30, X['PhysHlth'])\n","\n","robust_features = ['BMI', 'MentHlth', 'PhysHlth']\n","minmax_features = ['Age', 'Education', 'Income', 'GenHlth']\n","\n","scaler_robust = RobustScaler()\n","scaler_minmax = MinMaxScaler()\n","\n","X[robust_features] = scaler_robust.fit_transform(X[robust_features])\n","X[minmax_features] = scaler_minmax.fit_transform(X[minmax_features])\n","\n","# 5. Split Data untuk AE\n","X_train_ae, X_test_ae = train_test_split(X, test_size=0.2, random_state=SEED)\n","\n","# 6. Build Autoencoder AE C2 with LeakyReLU\n","input_dim = X.shape[1]\n","input_layer = Input(shape=(input_dim,))\n","\n","x = Dense(14)(input_layer)\n","x = LeakyReLU(alpha=0.1)(x)\n","x = Dense(10)(x)\n","x = LeakyReLU(alpha=0.1)(x)\n","\n","latent = Dense(8)(x)\n","latent = LeakyReLU(alpha=0.1)(latent)\n","\n","x = Dense(10)(latent)\n","x = LeakyReLU(alpha=0.1)(x)\n","x = Dense(14)(x)\n","x = LeakyReLU(alpha=0.1)(x)\n","\n","output_layer = Dense(input_dim, activation='linear')(x)\n","\n","autoencoder = Model(inputs=input_layer, outputs=output_layer)\n","autoencoder.compile(optimizer='adam', loss='mse')\n","\n","# 7. Train Autoencoder\n","history = autoencoder.fit(\n","    X_train_ae, X_train_ae,\n","    validation_data=(X_test_ae, X_test_ae),\n","    epochs=100,\n","    batch_size=50,\n","    verbose=1,\n","    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",")\n","\n","# 8. Simpan Model\n","save_dir = '/content/drive/MyDrive/Colab Notebooks/Skripsi/Model/Model Autoencoders'\n","os.makedirs(save_dir, exist_ok=True)\n","# autoencoder.save(f'{save_dir}/aec2_model_leakyrelu.h5')\n","\n","# 9. Ekstrak Encoder\n","encoder = Model(inputs=input_layer, outputs=latent)\n","\n","# 10. Transformasi seluruh data X ke bentuk laten\n","X_latent = encoder.predict(X)\n","\n","# 11. Buat DataFrame hasil reduksi dimensi\n","latent_df = pd.DataFrame(X_latent, columns=[f'Latent_{i+1}' for i in range(X_latent.shape[1])])\n","\n","# 12. Tambahkan label\n","latent_df['Diabetes_012'] = data['Diabetes_012']\n","\n","# 13. Simpan ke direktori\n","output_path = '/content/drive/MyDrive/Colab Notebooks/Skripsi/Dataset/V2 Hasil Eksperimen/AE'\n","os.makedirs(output_path, exist_ok=True)\n","latent_df.to_csv(f'{output_path}/AEC2_dataset_latent.csv', index=False)\n","\n","print(\"✅ Dataset latent berhasil disimpan dengan LeakyReLU.\")\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP5hTN1TB0ky04fJl5nun/C"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}