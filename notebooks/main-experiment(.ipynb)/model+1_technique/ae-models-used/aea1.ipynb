{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPFSAIIlBQYpIStyRC5YBkh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ebzpgjFZZ6Mx","executionInfo":{"status":"ok","timestamp":1751271773504,"user_tz":-420,"elapsed":827053,"user":{"displayName":"RIO LIANDO ANGGERI -","userId":"11047377438386479425"}},"outputId":"916dbfbf-3300-4802-a8e9-ce054658b8bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.2480 - val_loss: 0.0367\n","Epoch 2/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0332 - val_loss: 0.0252\n","Epoch 3/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0240 - val_loss: 0.0220\n","Epoch 4/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0209 - val_loss: 0.0195\n","Epoch 5/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0193 - val_loss: 0.0180\n","Epoch 6/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0174 - val_loss: 0.0167\n","Epoch 7/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0163 - val_loss: 0.0164\n","Epoch 8/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0161 - val_loss: 0.0164\n","Epoch 9/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0160 - val_loss: 0.0164\n","Epoch 10/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0159 - val_loss: 0.0169\n","Epoch 11/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0159 - val_loss: 0.0161\n","Epoch 12/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0158 - val_loss: 0.0158\n","Epoch 13/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0158 - val_loss: 0.0168\n","Epoch 14/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0158 - val_loss: 0.0158\n","Epoch 15/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0157 - val_loss: 0.0156\n","Epoch 16/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0156 - val_loss: 0.0151\n","Epoch 17/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - val_loss: 0.0130\n","Epoch 18/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0130 - val_loss: 0.0130\n","Epoch 19/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0128 - val_loss: 0.0127\n","Epoch 20/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0126 - val_loss: 0.0127\n","Epoch 21/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0126 - val_loss: 0.0126\n","Epoch 22/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0125 - val_loss: 0.0125\n","Epoch 23/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0124 - val_loss: 0.0125\n","Epoch 24/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0125\n","Epoch 25/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0124 - val_loss: 0.0124\n","Epoch 26/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0123 - val_loss: 0.0125\n","Epoch 27/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0123 - val_loss: 0.0124\n","Epoch 28/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0123 - val_loss: 0.0124\n","Epoch 29/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0123 - val_loss: 0.0124\n","Epoch 30/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0123 - val_loss: 0.0124\n","Epoch 31/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0123 - val_loss: 0.0123\n","Epoch 32/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0122 - val_loss: 0.0124\n","Epoch 33/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0122 - val_loss: 0.0124\n","Epoch 34/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0123\n","Epoch 35/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0122 - val_loss: 0.0123\n","Epoch 36/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0122 - val_loss: 0.0123\n","Epoch 37/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0122 - val_loss: 0.0123\n","Epoch 38/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0122 - val_loss: 0.0123\n","Epoch 39/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0123\n","Epoch 40/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0122 - val_loss: 0.0123\n","Epoch 41/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0121 - val_loss: 0.0123\n","Epoch 42/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0121 - val_loss: 0.0110\n","Epoch 43/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0104\n","Epoch 44/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0103 - val_loss: 0.0104\n","Epoch 45/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0104\n","Epoch 46/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0102 - val_loss: 0.0104\n","Epoch 47/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0102 - val_loss: 0.0103\n","Epoch 48/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0102 - val_loss: 0.0102\n","Epoch 49/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0101\n","Epoch 50/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0100\n","Epoch 51/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0100\n","Epoch 52/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0101\n","Epoch 53/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0100\n","Epoch 54/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0101\n","Epoch 55/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0101\n","Epoch 56/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0101\n","\u001b[1m7928/7928\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step\n","✅ Dataset latent berhasil disimpan.\n"]}],"source":["# 0. Mounting Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 1. Import Libraries\n","import numpy as np\n","import pandas as pd\n","import os\n","import random\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, RobustScaler\n","from scipy.stats.mstats import winsorize\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, LeakyReLU\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# 2. Set Seed untuk Konsistensi\n","SEED = 44\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","\n","# 3. Load Dataset\n","data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Skripsi/Dataset/diabetes_012_health_indicators_BRFSS2015.csv')\n","X = data.drop('Diabetes_012', axis=1)\n","\n","# 4. Preprocessing (Sesuai Model Default)\n","X['BMI'] = winsorize(X['BMI'], limits=[0.005, 0.005])\n","X['MentHlth'] = np.where(X['MentHlth'] > 30, 30, X['MentHlth'])\n","X['PhysHlth'] = np.where(X['PhysHlth'] > 30, 30, X['PhysHlth'])\n","\n","robust_features = ['BMI', 'MentHlth', 'PhysHlth']\n","minmax_features = ['Age', 'Education', 'Income', 'GenHlth']\n","\n","scaler_robust = RobustScaler()\n","scaler_minmax = MinMaxScaler()\n","\n","X[robust_features] = scaler_robust.fit_transform(X[robust_features])\n","X[minmax_features] = scaler_minmax.fit_transform(X[minmax_features])\n","\n","# 5. Split Data untuk AE (tidak butuh label y)\n","X_train_ae, X_test_ae = train_test_split(X, test_size=0.2, random_state=SEED)\n","\n","# 6. Build Autoencoder AE A1\n","input_dim = X.shape[1]\n","input_layer = Input(shape=(input_dim,))\n","\n","# Encoder\n","x = Dense(18)(input_layer)\n","x = LeakyReLU(alpha=0.1)(x)\n","x = Dense(16)(x)\n","x = LeakyReLU(alpha=0.1)(x)\n","\n","# Latent space\n","latent = Dense(14)(x)\n","latent = LeakyReLU(alpha=0.1)(latent)\n","\n","# Decoder\n","x = Dense(16)(latent)\n","x = LeakyReLU(alpha=0.1)(x)\n","x = Dense(18)(x)\n","x = LeakyReLU(alpha=0.1)(x)\n","\n","output_layer = Dense(input_dim, activation='linear')(x)\n","\n","autoencoder = Model(inputs=input_layer, outputs=output_layer)\n","autoencoder.compile(optimizer='adam', loss='mse')\n","\n","# 7. Train Autoencoder\n","history = autoencoder.fit(\n","    X_train_ae, X_train_ae,\n","    validation_data=(X_test_ae, X_test_ae),\n","    epochs=100,\n","    batch_size=50,\n","    verbose=1,\n","    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",")\n","\n","# 8. Simpan Model\n","save_dir = '/content/drive/MyDrive/Colab Notebooks/Skripsi/Model/Model Autoencoders'\n","os.makedirs(save_dir, exist_ok=True)\n","# autoencoder.save(f'{save_dir}/aes1_model.h5')\n","\n","# 9. Ekstrak Encoder dari Autoencoder\n","encoder = Model(inputs=input_layer, outputs=latent)\n","\n","# 10. Transformasi seluruh data X menjadi bentuk laten\n","X_latent = encoder.predict(X)\n","\n","# 11. Buat DataFrame hasil reduksi dimensi\n","latent_df = pd.DataFrame(X_latent, columns=[f'Latent_{i+1}' for i in range(X_latent.shape[1])])\n","\n","# 12. Tambahkan label (opsional)\n","latent_df['Diabetes_012'] = data['Diabetes_012']\n","\n","# 13. Simpan ke direktori yang ditentukan\n","output_path = '/content/drive/MyDrive/Colab Notebooks/Skripsi/Dataset/V2 Hasil Eksperimen/AE'\n","os.makedirs(output_path, exist_ok=True)\n","latent_df.to_csv(f'{output_path}/AEA1_dataset_latent.csv', index=False)\n","\n","print(\"✅ Dataset latent berhasil disimpan.\")\n"]}]}