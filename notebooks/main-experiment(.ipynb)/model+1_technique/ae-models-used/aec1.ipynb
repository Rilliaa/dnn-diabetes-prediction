{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPRG3PERWXUiTf5r2taX8Zv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"c_v-PpZF0EUc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751275422602,"user_tz":-420,"elapsed":264347,"user":{"displayName":"RIO LIANDO ANGGERI -","userId":"11047377438386479425"}},"outputId":"8703b1fe-d7b2-44d6-b892-b0c375c9cacd"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Epoch 1/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.2889 - val_loss: 0.0603\n","Epoch 2/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0568 - val_loss: 0.0475\n","Epoch 3/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0453 - val_loss: 0.0416\n","Epoch 4/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0409 - val_loss: 0.0401\n","Epoch 5/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0401 - val_loss: 0.0398\n","Epoch 6/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0398 - val_loss: 0.0395\n","Epoch 7/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0396 - val_loss: 0.0391\n","Epoch 8/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0369 - val_loss: 0.0335\n","Epoch 9/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0332 - val_loss: 0.0322\n","Epoch 10/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0322 - val_loss: 0.0319\n","Epoch 11/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 0.0320 - val_loss: 0.0319\n","Epoch 12/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0319 - val_loss: 0.0318\n","Epoch 13/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0319 - val_loss: 0.0318\n","Epoch 14/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 0.0319 - val_loss: 0.0318\n","Epoch 15/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0319 - val_loss: 0.0318\n","Epoch 16/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0318 - val_loss: 0.0318\n","Epoch 17/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 0.0318 - val_loss: 0.0318\n","Epoch 18/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0318 - val_loss: 0.0318\n","Epoch 19/100\n","\u001b[1m4059/4059\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0318 - val_loss: 0.0318\n","\u001b[1m7928/7928\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n","✅ Dataset latent berhasil disimpan.\n"]}],"source":["# 0. Mounting Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 1. Import Libraries\n","import numpy as np\n","import pandas as pd\n","import os\n","import random\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, RobustScaler\n","from scipy.stats.mstats import winsorize\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, LeakyReLU\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# 2. Set Seed untuk Konsistensi\n","SEED = 44\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","\n","# 3. Load Dataset\n","data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Skripsi/Dataset/diabetes_012_health_indicators_BRFSS2015.csv')\n","X = data.drop('Diabetes_012', axis=1)\n","\n","# 4. Preprocessing (Sesuai Model Default)\n","X['BMI'] = winsorize(X['BMI'], limits=[0.005, 0.005])\n","X['MentHlth'] = np.where(X['MentHlth'] > 30, 30, X['MentHlth'])\n","X['PhysHlth'] = np.where(X['PhysHlth'] > 30, 30, X['PhysHlth'])\n","\n","robust_features = ['BMI', 'MentHlth', 'PhysHlth']\n","minmax_features = ['Age', 'Education', 'Income', 'GenHlth']\n","\n","scaler_robust = RobustScaler()\n","scaler_minmax = MinMaxScaler()\n","\n","X[robust_features] = scaler_robust.fit_transform(X[robust_features])\n","X[minmax_features] = scaler_minmax.fit_transform(X[minmax_features])\n","\n","# 5. Split Data untuk AE\n","X_train_ae, X_test_ae = train_test_split(X, test_size=0.2, random_state=SEED)\n","\n","# 6. Build Autoencoder AEC1 dengan LeakyReLU\n","input_dim = X.shape[1]\n","input_layer = Input(shape=(input_dim,))\n","\n","# Encoder\n","x = Dense(14)(input_layer)\n","x = LeakyReLU(alpha=0.1)(x)\n","x = Dense(12)(x)\n","x = LeakyReLU(alpha=0.1)(x)\n","\n","# Latent space\n","latent = Dense(10)(x)\n","latent = LeakyReLU(alpha=0.1)(latent)\n","\n","# Decoder\n","x = Dense(12)(latent)\n","x = LeakyReLU(alpha=0.1)(x)\n","x = Dense(14)(x)\n","x = LeakyReLU(alpha=0.1)(x)\n","\n","# Output\n","output_layer = Dense(input_dim, activation='linear')(x)\n","\n","# Model\n","autoencoder = Model(inputs=input_layer, outputs=output_layer)\n","autoencoder.compile(optimizer='adam', loss='mse')\n","\n","# 7. Train Autoencoder\n","history = autoencoder.fit(\n","    X_train_ae, X_train_ae,\n","    validation_data=(X_test_ae, X_test_ae),\n","    epochs=100,\n","    batch_size=50,\n","    verbose=1,\n","    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",")\n","\n","# 8. Simpan Model\n","save_dir = '/content/drive/MyDrive/Colab Notebooks/Skripsi/Model/Model Autoencoders'\n","os.makedirs(save_dir, exist_ok=True)\n","# autoencoder.save(f'{save_dir}/aec1_model_leakyrelu.h5')\n","\n","# 9. Ekstrak Encoder\n","encoder = Model(inputs=input_layer, outputs=latent)\n","\n","# 10. Transformasi seluruh data X ke bentuk laten\n","X_latent = encoder.predict(X)\n","\n","# 11. Buat DataFrame hasil reduksi dimensi\n","latent_df = pd.DataFrame(X_latent, columns=[f'Latent_{i+1}' for i in range(X_latent.shape[1])])\n","\n","# 12. Tambahkan label\n","latent_df['Diabetes_012'] = data['Diabetes_012']\n","\n","# 13. Simpan hasil ke direktori\n","output_path = '/content/drive/MyDrive/Colab Notebooks/Skripsi/Dataset/V2 Hasil Eksperimen/AE'\n","os.makedirs(output_path, exist_ok=True)\n","latent_df.to_csv(f'{output_path}/AEC1_dataset_latent.csv', index=False)\n","\n","print(\"✅ Dataset latent berhasil disimpan.\")\n"]}]}