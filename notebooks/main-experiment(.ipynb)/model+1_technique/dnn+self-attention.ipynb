{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO782fEhyECL+efi6OQoo4L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYrIW8kgVVrX","executionInfo":{"status":"ok","timestamp":1751186816340,"user_tz":-420,"elapsed":342515,"user":{"displayName":"RIO LIANDO ANGGERI -","userId":"11047377438386479425"}},"outputId":"615deeb6-f086-493e-a84d-5ddc6e86a0bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Epoch 1/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8366 - loss: 0.4330 - val_accuracy: 0.8490 - val_loss: 0.4008\n","Epoch 2/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 7ms/step - accuracy: 0.8479 - loss: 0.3975 - val_accuracy: 0.8488 - val_loss: 0.3999\n","Epoch 3/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8487 - loss: 0.3958 - val_accuracy: 0.8492 - val_loss: 0.3997\n","Epoch 4/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8487 - loss: 0.3947 - val_accuracy: 0.8490 - val_loss: 0.3990\n","Epoch 5/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8486 - loss: 0.3940 - val_accuracy: 0.8488 - val_loss: 0.3985\n","Epoch 6/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.8489 - loss: 0.3934 - val_accuracy: 0.8491 - val_loss: 0.3990\n","Epoch 7/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.8491 - loss: 0.3929 - val_accuracy: 0.8490 - val_loss: 0.3988\n","Epoch 8/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8493 - loss: 0.3924 - val_accuracy: 0.8487 - val_loss: 0.3991\n","Epoch 9/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8499 - loss: 0.3920 - val_accuracy: 0.8494 - val_loss: 0.3990\n","Epoch 10/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8501 - loss: 0.3915 - val_accuracy: 0.8492 - val_loss: 0.3983\n","Epoch 11/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8501 - loss: 0.3911 - val_accuracy: 0.8494 - val_loss: 0.3993\n","Epoch 12/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8502 - loss: 0.3908 - val_accuracy: 0.8498 - val_loss: 0.3993\n","Epoch 13/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.8504 - loss: 0.3904 - val_accuracy: 0.8498 - val_loss: 0.3991\n","Epoch 14/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8504 - loss: 0.3901 - val_accuracy: 0.8495 - val_loss: 0.3995\n","Epoch 15/100\n","\u001b[1m3248/3248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8504 - loss: 0.3898 - val_accuracy: 0.8496 - val_loss: 0.3996\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n","\n","=== Classification Report (Macro) DNN + SA ===\n","              precision    recall  f1-score   support\n","\n","           0     0.8639    0.9775    0.9172     42741\n","           1     0.0000    0.0000    0.0000       926\n","           2     0.5574    0.1874    0.2805      7069\n","\n","    accuracy                         0.8496     50736\n","   macro avg     0.4738    0.3883    0.3992     50736\n","weighted avg     0.8054    0.8496    0.8117     50736\n","\n","\n","Macro-average ROC AUC: 0.7863\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["# 0. Mounting Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 1. Import Libraries\n","import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, RobustScaler\n","from sklearn.metrics import classification_report, roc_auc_score\n","from scipy.stats.mstats import winsorize\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, MultiHeadAttention, LayerNormalization, Dropout, Lambda\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# 2. Set Seed untuk Konsistensi\n","SEED = 44\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","\n","# 3. Load Dataset\n","data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Skripsi/Dataset/diabetes_012_health_indicators_BRFSS2015.csv')\n","X = data.drop('Diabetes_012', axis=1)\n","y = data['Diabetes_012']\n","\n","# 4. Preprocessing\n","X['BMI'] = winsorize(X['BMI'], limits=[0.005, 0.005])\n","X['MentHlth'] = np.where(X['MentHlth'] > 30, 30, X['MentHlth'])\n","X['PhysHlth'] = np.where(X['PhysHlth'] > 30, 30, X['PhysHlth'])\n","\n","robust_features = ['BMI', 'MentHlth', 'PhysHlth']\n","minmax_features = ['Age', 'Education', 'Income', 'GenHlth']\n","\n","scaler_robust = RobustScaler()\n","scaler_minmax = MinMaxScaler()\n","X[robust_features] = scaler_robust.fit_transform(X[robust_features])\n","X[minmax_features] = scaler_minmax.fit_transform(X[minmax_features])\n","\n","# 5. One-hot Encoding untuk Target\n","y_encoded = to_categorical(y)\n","\n","# 6. Split Data (Train/Test -> Train/Val)\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y_encoded, test_size=0.2, random_state=SEED, stratify=y\n",")\n","X_train_main, X_val, y_train_main, y_val = train_test_split(\n","    X_train, y_train, test_size=0.2, random_state=SEED, stratify=y_train.argmax(axis=1)\n",")\n","\n","# 7. Build DNN + Self-Attention Layer (Moved before Output Layer)\n","input_layer = Input(shape=(X.shape[1],))\n","x = Dense(64, activation='relu')(input_layer)\n","x = Dense(32, activation='relu')(x)\n","x = Dense(16, activation='relu')(x)\n","\n","# Expand dimensi untuk Self-Attention\n","x_expanded = Lambda(lambda t: tf.expand_dims(t, axis=1))(x)\n","\n","# Self-Attention sebelum output\n","attn_output = MultiHeadAttention(num_heads=4, key_dim=4)(x_expanded, x_expanded)\n","attn_output = LayerNormalization()(attn_output + x_expanded)\n","\n","# Kembalikan ke bentuk 2D\n","attn_output_squeezed = Lambda(lambda t: tf.squeeze(t, axis=1))(attn_output)\n","\n","# Output layer\n","output_layer = Dense(3, activation='softmax')(attn_output_squeezed)\n","\n","# Final Model\n","model_sa = Model(inputs=input_layer, outputs=output_layer)\n","model_sa.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# 8. Train Model (Updated Epochs: 100)\n","early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","history_sa = model_sa.fit(\n","    X_train_main, y_train_main,\n","    validation_data=(X_val, y_val),\n","    epochs=100,\n","    batch_size=50,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","# 9. Evaluate\n","y_pred_prob_sa = model_sa.predict(X_test)\n","y_pred_class_sa = np.argmax(y_pred_prob_sa, axis=1)\n","y_true_class_sa = np.argmax(y_test, axis=1)\n","\n","print(\"\\n=== Classification Report (Macro) DNN + SA ===\")\n","print(classification_report(y_true_class_sa, y_pred_class_sa, digits=4))\n","roc_auc_sa = roc_auc_score(y_test, y_pred_prob_sa, average='macro', multi_class='ovr')\n","print(f\"\\nMacro-average ROC AUC: {roc_auc_sa:.4f}\")\n"]}]}