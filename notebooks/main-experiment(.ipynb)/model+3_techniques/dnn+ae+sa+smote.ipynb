{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM5/EogcXnGIPOkY/c3CK70"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPfcKEIvJQg3","executionInfo":{"status":"ok","timestamp":1751379951415,"user_tz":-420,"elapsed":351289,"user":{"displayName":"RIO LIANDO ANGGERI -","userId":"11047377438386479425"}},"outputId":"e845c4cd-73f8-494b-8d72-7782174f9007"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Epoch 1/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 5ms/step - accuracy: 0.4906 - loss: 0.9881 - val_accuracy: 0.5143 - val_loss: 0.9616\n","Epoch 2/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.5104 - loss: 0.9653 - val_accuracy: 0.5254 - val_loss: 0.9468\n","Epoch 3/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.5195 - loss: 0.9513 - val_accuracy: 0.5307 - val_loss: 0.9377\n","Epoch 4/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.5254 - loss: 0.9433 - val_accuracy: 0.5330 - val_loss: 0.9349\n","Epoch 5/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.5288 - loss: 0.9386 - val_accuracy: 0.5385 - val_loss: 0.9287\n","Epoch 6/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.5325 - loss: 0.9344 - val_accuracy: 0.5408 - val_loss: 0.9215\n","Epoch 7/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.5357 - loss: 0.9301 - val_accuracy: 0.5416 - val_loss: 0.9192\n","Epoch 8/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.5386 - loss: 0.9261 - val_accuracy: 0.5458 - val_loss: 0.9143\n","Epoch 9/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.5420 - loss: 0.9226 - val_accuracy: 0.5466 - val_loss: 0.9136\n","Epoch 10/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.5450 - loss: 0.9190 - val_accuracy: 0.5510 - val_loss: 0.9081\n","Epoch 11/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5ms/step - accuracy: 0.5472 - loss: 0.9162 - val_accuracy: 0.5504 - val_loss: 0.9078\n","Epoch 12/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.5490 - loss: 0.9136 - val_accuracy: 0.5544 - val_loss: 0.9056\n","Epoch 13/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.5514 - loss: 0.9115 - val_accuracy: 0.5578 - val_loss: 0.9017\n","Epoch 14/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 5ms/step - accuracy: 0.5532 - loss: 0.9094 - val_accuracy: 0.5602 - val_loss: 0.8987\n","Epoch 15/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.5542 - loss: 0.9078 - val_accuracy: 0.5597 - val_loss: 0.8966\n","Epoch 16/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.5565 - loss: 0.9056 - val_accuracy: 0.5623 - val_loss: 0.8948\n","Epoch 17/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5ms/step - accuracy: 0.5583 - loss: 0.9039 - val_accuracy: 0.5614 - val_loss: 0.8959\n","Epoch 18/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.5598 - loss: 0.9025 - val_accuracy: 0.5613 - val_loss: 0.8951\n","Epoch 19/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.5610 - loss: 0.9007 - val_accuracy: 0.5652 - val_loss: 0.8905\n","Epoch 20/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.5622 - loss: 0.8992 - val_accuracy: 0.5663 - val_loss: 0.8893\n","Epoch 21/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.5629 - loss: 0.8980 - val_accuracy: 0.5656 - val_loss: 0.8890\n","Epoch 22/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.5644 - loss: 0.8962 - val_accuracy: 0.5664 - val_loss: 0.8884\n","Epoch 23/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.5655 - loss: 0.8948 - val_accuracy: 0.5652 - val_loss: 0.8905\n","Epoch 24/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 6ms/step - accuracy: 0.5660 - loss: 0.8938 - val_accuracy: 0.5665 - val_loss: 0.8890\n","Epoch 25/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 5ms/step - accuracy: 0.5664 - loss: 0.8924 - val_accuracy: 0.5671 - val_loss: 0.8882\n","Epoch 26/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 5ms/step - accuracy: 0.5685 - loss: 0.8909 - val_accuracy: 0.5667 - val_loss: 0.8902\n","Epoch 27/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.5696 - loss: 0.8897 - val_accuracy: 0.5698 - val_loss: 0.8858\n","Epoch 28/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.5702 - loss: 0.8882 - val_accuracy: 0.5694 - val_loss: 0.8877\n","Epoch 29/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.5713 - loss: 0.8871 - val_accuracy: 0.5694 - val_loss: 0.8854\n","Epoch 30/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - accuracy: 0.5709 - loss: 0.8864 - val_accuracy: 0.5708 - val_loss: 0.8866\n","Epoch 31/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.5724 - loss: 0.8851 - val_accuracy: 0.5742 - val_loss: 0.8814\n","Epoch 32/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.5743 - loss: 0.8838 - val_accuracy: 0.5730 - val_loss: 0.8836\n","Epoch 33/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.5745 - loss: 0.8827 - val_accuracy: 0.5754 - val_loss: 0.8808\n","Epoch 34/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.5760 - loss: 0.8815 - val_accuracy: 0.5765 - val_loss: 0.8782\n","Epoch 35/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.5769 - loss: 0.8801 - val_accuracy: 0.5771 - val_loss: 0.8771\n","Epoch 36/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.5787 - loss: 0.8787 - val_accuracy: 0.5767 - val_loss: 0.8797\n","Epoch 37/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.5793 - loss: 0.8770 - val_accuracy: 0.5810 - val_loss: 0.8763\n","Epoch 38/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.5819 - loss: 0.8746 - val_accuracy: 0.5819 - val_loss: 0.8736\n","Epoch 39/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.5841 - loss: 0.8722 - val_accuracy: 0.5851 - val_loss: 0.8693\n","Epoch 40/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.5851 - loss: 0.8702 - val_accuracy: 0.5846 - val_loss: 0.8699\n","Epoch 41/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.5866 - loss: 0.8683 - val_accuracy: 0.5858 - val_loss: 0.8678\n","Epoch 42/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.5889 - loss: 0.8664 - val_accuracy: 0.5875 - val_loss: 0.8646\n","Epoch 43/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.5899 - loss: 0.8646 - val_accuracy: 0.5899 - val_loss: 0.8634\n","Epoch 44/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.5907 - loss: 0.8631 - val_accuracy: 0.5897 - val_loss: 0.8644\n","Epoch 45/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.5914 - loss: 0.8618 - val_accuracy: 0.5914 - val_loss: 0.8621\n","Epoch 46/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.5922 - loss: 0.8604 - val_accuracy: 0.5926 - val_loss: 0.8596\n","Epoch 47/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.5928 - loss: 0.8597 - val_accuracy: 0.5931 - val_loss: 0.8560\n","Epoch 48/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.5938 - loss: 0.8584 - val_accuracy: 0.5920 - val_loss: 0.8591\n","Epoch 49/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.5936 - loss: 0.8576 - val_accuracy: 0.5955 - val_loss: 0.8546\n","Epoch 50/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.5949 - loss: 0.8565 - val_accuracy: 0.5952 - val_loss: 0.8542\n","Epoch 51/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.5948 - loss: 0.8556 - val_accuracy: 0.5933 - val_loss: 0.8569\n","Epoch 52/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4ms/step - accuracy: 0.5955 - loss: 0.8548 - val_accuracy: 0.5945 - val_loss: 0.8545\n","Epoch 53/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.5961 - loss: 0.8540 - val_accuracy: 0.5951 - val_loss: 0.8536\n","Epoch 54/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.5966 - loss: 0.8530 - val_accuracy: 0.5960 - val_loss: 0.8514\n","Epoch 55/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.5965 - loss: 0.8524 - val_accuracy: 0.5939 - val_loss: 0.8548\n","Epoch 56/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.5970 - loss: 0.8515 - val_accuracy: 0.5958 - val_loss: 0.8526\n","Epoch 57/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.5974 - loss: 0.8507 - val_accuracy: 0.5936 - val_loss: 0.8555\n","Epoch 58/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.5976 - loss: 0.8503 - val_accuracy: 0.5965 - val_loss: 0.8502\n","Epoch 59/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.5980 - loss: 0.8494 - val_accuracy: 0.5952 - val_loss: 0.8526\n","Epoch 60/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.5982 - loss: 0.8491 - val_accuracy: 0.5963 - val_loss: 0.8524\n","Epoch 61/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.5986 - loss: 0.8484 - val_accuracy: 0.5948 - val_loss: 0.8517\n","Epoch 62/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.5992 - loss: 0.8477 - val_accuracy: 0.5976 - val_loss: 0.8509\n","Epoch 63/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - accuracy: 0.5999 - loss: 0.8469 - val_accuracy: 0.5978 - val_loss: 0.8493\n","Epoch 64/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.6003 - loss: 0.8458 - val_accuracy: 0.5976 - val_loss: 0.8502\n","Epoch 65/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.6005 - loss: 0.8451 - val_accuracy: 0.5976 - val_loss: 0.8509\n","Epoch 66/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.6010 - loss: 0.8442 - val_accuracy: 0.6020 - val_loss: 0.8452\n","Epoch 67/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.6014 - loss: 0.8435 - val_accuracy: 0.6011 - val_loss: 0.8467\n","Epoch 68/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.6020 - loss: 0.8425 - val_accuracy: 0.6012 - val_loss: 0.8451\n","Epoch 69/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.6021 - loss: 0.8417 - val_accuracy: 0.5983 - val_loss: 0.8482\n","Epoch 70/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - accuracy: 0.6030 - loss: 0.8412 - val_accuracy: 0.6018 - val_loss: 0.8432\n","Epoch 71/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.6029 - loss: 0.8405 - val_accuracy: 0.5999 - val_loss: 0.8504\n","Epoch 72/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.6034 - loss: 0.8401 - val_accuracy: 0.6011 - val_loss: 0.8463\n","Epoch 73/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.6035 - loss: 0.8394 - val_accuracy: 0.6019 - val_loss: 0.8436\n","Epoch 74/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.6042 - loss: 0.8389 - val_accuracy: 0.6010 - val_loss: 0.8442\n","Epoch 75/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.6039 - loss: 0.8384 - val_accuracy: 0.6026 - val_loss: 0.8430\n","Epoch 76/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.6051 - loss: 0.8380 - val_accuracy: 0.6014 - val_loss: 0.8451\n","Epoch 77/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.6055 - loss: 0.8373 - val_accuracy: 0.6006 - val_loss: 0.8445\n","Epoch 78/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.6049 - loss: 0.8371 - val_accuracy: 0.5984 - val_loss: 0.8490\n","Epoch 79/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.6055 - loss: 0.8366 - val_accuracy: 0.6023 - val_loss: 0.8413\n","Epoch 80/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.6058 - loss: 0.8359 - val_accuracy: 0.6029 - val_loss: 0.8433\n","Epoch 81/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.6060 - loss: 0.8355 - val_accuracy: 0.6008 - val_loss: 0.8447\n","Epoch 82/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.6067 - loss: 0.8349 - val_accuracy: 0.6030 - val_loss: 0.8401\n","Epoch 83/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.6064 - loss: 0.8344 - val_accuracy: 0.6017 - val_loss: 0.8429\n","Epoch 84/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.6069 - loss: 0.8342 - val_accuracy: 0.6030 - val_loss: 0.8409\n","Epoch 85/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.6072 - loss: 0.8337 - val_accuracy: 0.6010 - val_loss: 0.8459\n","Epoch 86/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.6080 - loss: 0.8332 - val_accuracy: 0.6013 - val_loss: 0.8414\n","Epoch 87/100\n","\u001b[1m8207/8207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.6083 - loss: 0.8327 - val_accuracy: 0.6023 - val_loss: 0.8424\n","\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n","\n","=== Classification Report (Macro) Model DNN + SMOTE + SA ===\n","              precision    recall  f1-score   support\n","\n","           0     0.9416    0.6613    0.7769     42741\n","           1     0.0277    0.2603    0.0501       926\n","           2     0.3224    0.5480    0.4060      7069\n","\n","    accuracy                         0.6382     50736\n","   macro avg     0.4306    0.4899    0.4110     50736\n","weighted avg     0.8386    0.6382    0.7120     50736\n","\n","\n","Macro-average ROC AUC: 0.7312\n"]}],"source":["# 0. Mounting Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 1. Import Libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import random\n","import os\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, RobustScaler\n","from sklearn.metrics import classification_report, roc_auc_score\n","from scipy.stats.mstats import winsorize\n","from imblearn.over_sampling import SMOTE\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, MultiHeadAttention, LayerNormalization, Lambda\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.utils import to_categorical\n","\n","# 2. Set Seed untuk Konsistensi\n","SEED = 44\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","\n","# 3. Load Dataset\n","data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Skripsi/Dataset/V2 Hasil Eksperimen/AE/AEB1_dataset_latent.csv')\n","X = data.drop('Diabetes_012', axis=1)\n","y = data['Diabetes_012']\n","\n","# 5. Split Data (Train/Test)\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=SEED, stratify=y\n",")\n","\n","# 6. SMOTE on Train Data Only\n","smote = SMOTE(random_state=SEED)\n","X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n","\n","\n","# 7. One-hot Encoding\n","y_train_encoded = to_categorical(y_train_smote)\n","y_test_encoded = to_categorical(y_test)\n","\n","# 8. Split Train → Train Main & Validation\n","X_train_main, X_val, y_train_main, y_val = train_test_split(\n","    X_train_smote, y_train_encoded, test_size=0.2, random_state=SEED, stratify=y_train_smote\n",")\n","\n","# 9. Build DNN + Self-Attention Model\n","input_layer = Input(shape=(X.shape[1],))\n","x = Dense(64, activation='relu')(input_layer)\n","x = Dense(32, activation='relu')(x)\n","x = Dense(16, activation='relu')(x)\n","\n","# Expand dimension for self-attention\n","x_expanded = Lambda(lambda t: tf.expand_dims(t, axis=1))(x)\n","\n","# Self-Attention Layer\n","attn_output = MultiHeadAttention(num_heads=4, key_dim=4)(x_expanded, x_expanded)\n","attn_output = LayerNormalization()(attn_output + x_expanded)\n","\n","# Flatten back to 2D\n","attn_output_squeezed = Lambda(lambda t: tf.squeeze(t, axis=1))(attn_output)\n","\n","# Output Layer\n","output_layer = Dense(3, activation='softmax')(attn_output_squeezed)\n","\n","# Final Model\n","model = Model(inputs=input_layer, outputs=output_layer)\n","\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# 10. Train Model\n","early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","history = model.fit(\n","    X_train_main, y_train_main,\n","    validation_data=(X_val, y_val),\n","    epochs=100,\n","    batch_size=50,\n","    callbacks=[early_stop],\n","    verbose=1\n",")\n","\n","# 11. Evaluate on Test Set\n","y_pred_prob = model.predict(X_test)\n","y_pred_class = np.argmax(y_pred_prob, axis=1)\n","y_true_class = np.argmax(y_test_encoded, axis=1)\n","\n","# 12. Metrik Evaluasi\n","print(\"\\n=== Classification Report (Macro) Model DNN + AE + SMOTE + SA ===\")\n","print(classification_report(y_true_class, y_pred_class, digits=4))\n","roc_auc = roc_auc_score(y_test_encoded, y_pred_prob, average='macro', multi_class='ovr')\n","print(f\"\\nMacro-average ROC AUC: {roc_auc:.4f}\")\n"]}]}