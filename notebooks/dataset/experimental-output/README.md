# [EN]

## Experimental datasets from optimized preprocessing techniques, prepared for DNN model training

This folder contains the processed datasets resulting from the experimental combinations of optimization techniques applied in this study. These datasets serve as input for training various versions of the Deep Neural Network (DNN) model. All datasets in this folder have undergone preprocessing steps, including normalization using Min-Max Scaling and Robust Scaler, as well as Winsorizing.

### The datasets are organized into three categories:
- **Autoencoders**: Datasets with reduced dimensionality using autoencoders.
- **SMOTE**: Datasets with balanced class distribution using Synthetic Minority Over-sampling Technique (SMOTE).
- **KCC + Autoencoders**: Datasets processed with feature selection using Kendall’s Correlation Coefficient (KCC) followed by dimensionality reduction using autoencoders.

Each subfolder represents a specific experiment path and supports the training and evaluation of a distinct model variant.

---
# [ID]

## Dataset hasil eksperimen dari kombinasi teknik akan disimpan untuk digunakan dalam pelatihan model DNN

Folder ini berisi output dataset dari hasil eksperimen kombinasi teknik optimasi yang digunakan dalam penelitian ini. Tujuannya adalah untuk menyediakan data input yang telah diproses dan siap digunakan dalam pelatihan model Deep Neural Network (DNN). Seluruh dataset dalam folder ini telah melalui tahapan praproses, yang mencakup normalisasi menggunakan Min-Max Scaling dan Robust Scaler, serta teknik Winsorizing untuk menangani nilai outlier.

### Dataset dikategorikan menjadi tiga jenis:
- **Autoencoders**: Dataset hasil reduksi dimensi menggunakan autoencoders.
- **SMOTE**: Dataset hasil penyeimbangan data menggunakan Synthetic Minority Over-sampling Technique (SMOTE).
- **KCC + Autoencoders**: Dataset hasil seleksi fitur menggunakan Kendall’s Correlation Coefficient (KCC), kemudian direduksi dimensinya menggunakan autoencoders.

Setiap folder mencerminkan satu jalur eksperimen dan mendukung proses pelatihan serta evaluasi model yang berbeda.


